{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_var(x, volatile=False):\n",
    "\tif torch.cuda.is_available():\n",
    "\t\tx = x.cuda()\n",
    "\n",
    "\treturn Variable(x, volatile=volatile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Encoder\"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "        nn.Conv2d(1, 32, kernel_size = 3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size = 3, stride=2, padding=1),\n",
    "        nn.ReLU(),  \n",
    "        ])\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"Extract the image feature vectors.\"\"\"\n",
    "        features = images\n",
    "        for layer in self.layers:\n",
    "            features = layer(features)\n",
    "        return features\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Decoder\"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "        nn.ConvTranspose2d(64, 32, 4, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.ConvTranspose2d(32, 1, 4, stride=2, padding=1),\n",
    "        nn.Sigmoid()\n",
    "        ])\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"Extract the image feature vectors.\"\"\"\n",
    "        features = images\n",
    "        for layer in self.layers:\n",
    "            features = layer(features)\n",
    "        return features\n",
    "\n",
    "class ClusterNet(nn.Module):\n",
    "\n",
    "    def __init__(self, n_clusters=10):\n",
    "        \"\"\"ClusterNet(\"\"\"\n",
    "        super(ClusterNet, self).__init__()\n",
    "        self.layers = nn.ModuleList([\n",
    "        nn.Conv2d(1, 32, kernel_size = 3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(32, 64, kernel_size = 3, stride=2, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(64, 64, kernel_size = 3, stride=2, padding=1),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.ReLU(),    \n",
    "        nn.Flatten(),\n",
    "        nn.Linear(256, n_clusters),          \n",
    "        nn.Softmax(dim=0),\n",
    "\n",
    "        ])\n",
    "\n",
    "    def forward(self, images):\n",
    "        \"\"\"Extract the image feature vectors.\"\"\"\n",
    "        features = images\n",
    "        for layer in self.layers:\n",
    "            features = layer(features)\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder(autoencoder, optimizer, criterion, data_loader, number_of_epochs=1, name='main', verbose=False):\n",
    "    print('Training %s ...'%(name))\n",
    "    for epoch in range(number_of_epochs):\n",
    "\n",
    "        running_loss = 0.0\n",
    "        autoencoder.train()\n",
    "        for batch_index, (in_images, labels) in enumerate(data_loader):\n",
    "            \n",
    "            in_images = to_var(in_images)\n",
    "            out_images = autoencoder(in_images)\n",
    "\n",
    "            loss = criterion(out_images, in_images)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data.numpy()\n",
    "            if batch_index % 100==0 and verbose:\n",
    "                print('epoch %d loss: %.5f batch: %d' % (epoch, running_loss/((batch_index + 1)), (batch_index + 1)*batch_size))\n",
    "            if batch_index != 0 and batch_index % 1000 == 0:\n",
    "                break\n",
    "    print('Done training %s'%(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "train_loader = DataLoader( \n",
    "    torchvision.datasets.MNIST('data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_loader = DataLoader( \n",
    "    torchvision.datasets.MNIST('data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor()\n",
    "                             ])),\n",
    "  batch_size=2000, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_autoencoder_mixture(train_loader, test_loader, n_clusters=10):\n",
    "    autoencoder_mixture = {}\n",
    "    \n",
    "    autoencoder_main = nn.Sequential(Encoder(), Decoder())\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(autoencoder_main.parameters(), lr=1e-3)\n",
    "    number_of_epochs = 5\n",
    "    \n",
    "    train_autoencoder(autoencoder_main , optimizer, criterion, train_loader, number_of_epochs, name='main')\n",
    "    \n",
    "    dataiter = iter(test_loader)\n",
    "    in_images = dataiter.next()[0]\n",
    "    autoencoder_main.eval()\n",
    "    init_data = autoencoder_main[0](to_var(in_images)).data.view(in_images.shape[0],-1).numpy()\n",
    "    \n",
    "    autoencoder_mixture['autoencoder_main'] = autoencoder_main\n",
    "    \n",
    "    print('Clustering ...')\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(init_data)\n",
    "    print('Done Clustering !!')\n",
    "    for cluster in range(n_clusters):\n",
    "        autoencoder_mixture[cluster] = {}\n",
    "        ds = AutoEncoderDataset(in_images[kmeans.labels_==cluster])\n",
    "        autoencoder_mixture[cluster]['autoencoder'] = nn.Sequential(Encoder(), Decoder())\n",
    "        optimizer = optim.Adam(autoencoder_mixture[cluster]['autoencoder'].parameters(), lr=1e-2)\n",
    "        criterion = nn.BCELoss()\n",
    "        data_loader = DataLoader(ds, batch_size=4, shuffle=True)\n",
    "        \n",
    "        train_autoencoder(autoencoder_mixture[cluster]['autoencoder'], \n",
    "                          optimizer,\n",
    "                          criterion,\n",
    "                          data_loader, \n",
    "                          number_of_epochs = 10, \n",
    "                          name='cluster_'+ str(cluster))\n",
    "        \n",
    "        test_image = iter(data_loader).next()[0]\n",
    "        autoencoder_mixture[cluster]['autoencoder'].eval()\n",
    "        recon_image = autoencoder_mixture[cluster]['autoencoder'](to_var(test_image))\n",
    "        plt.subplot(10, 10, cluster + 1)\n",
    "        plt.imshow(test_image[0].numpy().squeeze(0))\n",
    "        plt.subplot(10, 10, cluster + 11)\n",
    "        plt.imshow(recon_image[0].data.numpy().squeeze(0))\n",
    "    \n",
    "    autoencoder_mixture['cluster_net'] = ClusterNet()\n",
    "    plt.show()\n",
    "    return autoencoder_mixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training main ...\n",
      "Done training main\n",
      "Clustering ...\n",
      "Done Clustering !!\n",
      "Training cluster_0 ...\n",
      "Done training cluster_0\n",
      "Training cluster_1 ...\n",
      "Done training cluster_1\n",
      "Training cluster_2 ...\n",
      "Done training cluster_2\n",
      "Training cluster_3 ...\n",
      "Done training cluster_3\n",
      "Training cluster_4 ...\n",
      "Done training cluster_4\n",
      "Training cluster_5 ...\n",
      "Done training cluster_5\n",
      "Training cluster_6 ...\n",
      "Done training cluster_6\n",
      "Training cluster_7 ...\n",
      "Done training cluster_7\n",
      "Training cluster_8 ...\n",
      "Done training cluster_8\n",
      "Training cluster_9 ...\n",
      "Done training cluster_9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder_mixture = init_autoencoder_mixture(train_loader, test_loader, n_clusters=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mixure_output(autoencoder_mixture, images, n_clusters=10):\n",
    "    output = []\n",
    "    for cluster in range(n_clusters):\n",
    "        output.append(autoencoder_mixture[cluster]['autoencoder'](images))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_mixure_loss_fn(images, mixure_outputs, clustering_net_output, n_clusters=10):\n",
    "    loss = 0 \n",
    "    for cluster in range(n_clusters):\n",
    "        mse = -((mixure_outputs[cluster] - images)**2).mean(axis=(1, 2, 3))\n",
    "        loss += clustering_net_output[:, cluster] * torch.exp(mse) \n",
    "    loss = -torch.log(loss).sum()\n",
    "    return loss\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8536)\n"
     ]
    }
   ],
   "source": [
    "images = to_var(torch.rand(5, 1, 28, 28))\n",
    "mixure_outputs = [to_var(torch.rand(5, 1, 28, 28))]*10\n",
    "clustering_net_output = nn.functional.softmax(to_var(torch.randn(5, 10) +1 ), dim=1)\n",
    "\n",
    "print(autoencoder_mixure_loss_fn(images, mixure_outputs, clustering_net_output, n_clusters=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_autoencoder_mixure(autoencoder_mixture, data_loader, number_of_epochs=1, n_clusters = 10, name='main', verbose=False):\n",
    "    print('Training %s ...'%(name))\n",
    "\n",
    "    params = list(autoencoder_mixture['cluster_net'].parameters())\n",
    "    \n",
    "    for cluster in range(n_clusters):\n",
    "        params += list(autoencoder_mixture[cluster]['autoencoder'].parameters())        \n",
    "        autoencoder_mixture[cluster]['autoencoder'].train()\n",
    "        \n",
    "    optimizer = optim.Adam(params, lr=1e-2)\n",
    "    number_of_epochs = 5\n",
    "\n",
    "    for epoch in range(number_of_epochs):\n",
    "        running_loss = 0.0\n",
    "        autoencoder_mixture['cluster_net'].train()\n",
    "        \n",
    "        for batch_index, (in_images, labels) in enumerate(data_loader):\n",
    "\n",
    "            in_images = to_var(in_images)\n",
    "            mixure_outputs = get_mixure_output(autoencoder_mixture, in_images, n_clusters=10)\n",
    "            clustering_net_outputs = autoencoder_mixture['cluster_net'](in_images)\n",
    "            loss = autoencoder_mixure_loss_fn(in_images, mixure_outputs, clustering_net_outputs, n_clusters=10)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.data.numpy()\n",
    "            if batch_index % 100==0 and verbose:\n",
    "                print('epoch %d loss: %.5f batch: %d' % (epoch, running_loss/((batch_index + 1)), (batch_index + 1)*batch_size))\n",
    "            if batch_index != 0 and batch_index % 1000 == 0:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training autoencoder mixture ...\n",
      "epoch 0 loss: -1.77689 batch: 8\n",
      "epoch 0 loss: -1.77335 batch: 808\n",
      "epoch 0 loss: -1.77502 batch: 1608\n",
      "epoch 0 loss: -1.77598 batch: 2408\n",
      "epoch 0 loss: -1.77655 batch: 3208\n",
      "epoch 0 loss: -1.77693 batch: 4008\n",
      "epoch 0 loss: -1.77723 batch: 4808\n",
      "epoch 0 loss: -1.77752 batch: 5608\n",
      "epoch 0 loss: -1.77777 batch: 6408\n",
      "epoch 0 loss: -1.77801 batch: 7208\n",
      "epoch 0 loss: -1.77821 batch: 8008\n",
      "epoch 1 loss: -1.77959 batch: 8\n",
      "epoch 1 loss: -1.78023 batch: 808\n",
      "epoch 1 loss: -1.78038 batch: 1608\n",
      "epoch 1 loss: -1.78049 batch: 2408\n",
      "epoch 1 loss: -1.78054 batch: 3208\n",
      "epoch 1 loss: -1.78064 batch: 4008\n",
      "epoch 1 loss: -1.78072 batch: 4808\n",
      "epoch 1 loss: -1.78080 batch: 5608\n",
      "epoch 1 loss: -1.78086 batch: 6408\n",
      "epoch 1 loss: -1.78090 batch: 7208\n",
      "epoch 1 loss: -1.78096 batch: 8008\n",
      "epoch 2 loss: -1.78267 batch: 8\n",
      "epoch 2 loss: -1.78148 batch: 808\n",
      "epoch 2 loss: -1.78155 batch: 1608\n",
      "epoch 2 loss: -1.78155 batch: 2408\n",
      "epoch 2 loss: -1.78156 batch: 3208\n",
      "epoch 2 loss: -1.78162 batch: 4008\n",
      "epoch 2 loss: -1.78165 batch: 4808\n",
      "epoch 2 loss: -1.78169 batch: 5608\n",
      "epoch 2 loss: -1.78171 batch: 6408\n",
      "epoch 2 loss: -1.78174 batch: 7208\n",
      "epoch 2 loss: -1.78178 batch: 8008\n",
      "epoch 3 loss: -1.78231 batch: 8\n",
      "epoch 3 loss: -1.78208 batch: 808\n",
      "epoch 3 loss: -1.78213 batch: 1608\n",
      "epoch 3 loss: -1.78214 batch: 2408\n",
      "epoch 3 loss: -1.78219 batch: 3208\n",
      "epoch 3 loss: -1.78219 batch: 4008\n",
      "epoch 3 loss: -1.78223 batch: 4808\n",
      "epoch 3 loss: -1.78224 batch: 5608\n",
      "epoch 3 loss: -1.78225 batch: 6408\n",
      "epoch 3 loss: -1.78227 batch: 7208\n",
      "epoch 3 loss: -1.78230 batch: 8008\n",
      "epoch 4 loss: -1.78252 batch: 8\n",
      "epoch 4 loss: -1.78250 batch: 808\n",
      "epoch 4 loss: -1.78250 batch: 1608\n",
      "epoch 4 loss: -1.78251 batch: 2408\n",
      "epoch 4 loss: -1.78251 batch: 3208\n",
      "epoch 4 loss: -1.78252 batch: 4008\n",
      "epoch 4 loss: -1.78255 batch: 4808\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "train_autoencoder_mixure(autoencoder_mixture,  \n",
    "                         train_loader, \n",
    "                         number_of_epochs=1, \n",
    "                         name='autoencoder mixture', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
